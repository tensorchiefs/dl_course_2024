{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tGBEB7Pvd-0u"
   },
   "source": [
    "# Exercise on the value of unsupervised constructed features for training a classifier with few labeled examples: SOLUTION\n",
    "\n",
    "To get unsupervised constructed features of an image, we can use a pretrained CNN as feature extractor. \n",
    "\n",
    "We have done this to extract features from 100 Cifar10 images.  As pretrained CNN we use a VGG16 architecture that was trained on ImageNet data and was the second winner of the ImageNet competition in 2014. \n",
    "\n",
    "As a check on the quality of the feature representation of the CIFAR10 data, we will use once the pixel-features and once the VGG-features to train a classifier using this 100 labeled data (on average 10 per class). If the VGG-feature are indeed better than the raw pixel values, we would expect to achieve a better classifier when using the VGG-feature compared to the pixel feature.\n",
    "\n",
    "a) Which accuracy would you expect for a classifier which cannot distinguish between the 10 classes and is only guessing?\n",
    "\n",
    "**Solution: 10%**\n",
    "\n",
    "\n",
    "b) Go through the code which is used to set-up, train, and evaluate a CNN classifier using the raw pixel features. Discuss your thoughts on the achieved accuracy (e.g. with your neighbor).\n",
    "\n",
    "**Solution: The accuracy is with around 20% better then guessing but still very bad. However, this is not surprising since the resolution of the images are very low and it is alread by eye quite difficult to distinguish between the classes. Moreover, we have  only very few training examples (only 10 per class), quite bad features (the raw pixel values) and a model with many parameters (around 45k parameter).**\n",
    "\n",
    "b) Now we use the unsupervised constructed VGG features. We want to check, if these VGG features are good enough to train a classifier with only few labeled data and still get a satisfying performance. For this purpose, please complete the code to set up a fully connected NN and run the provided subsequent code to train it and determine its accuracy on the test set. Compare it to the accuracy which we achieve with a RF. Discuss the results (e.g. with your neighbor).\n",
    "\n",
    "**Solution: For code completion see below. The accuracy of the fcNN is with more than 55% much better than the accuray of the from scratch trained CNN which was 20%. This implies that the VGG-features are quite good and more informative than the raw pixel features. With the RF we achieve a similar performance.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PDJ_bt5Rd-02"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "85458Tp9d-02",
    "outputId": "4359ce5a-b7da-40a7-ff7b-fe4735dfceb7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras 2.4.0 TF 2.3.0 Python sys.version_info(major=3, minor=7, micro=11, releaselevel='final', serial=0)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as imgplot\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from pylab import *\n",
    "\n",
    "import time\n",
    "import tensorflow as tf\n",
    "\n",
    "import  tensorflow.keras as keras\n",
    "import sys\n",
    "print (\"Keras {} TF {} Python {}\".format(keras.__version__, tf.__version__, sys.version_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MUIuN6nOd-05"
   },
   "source": [
    "## CIFAR Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20_9rgUsd-05",
    "outputId": "5b0c1a30-d488-4d1d-e876-fdd2f9f3e663"
   },
   "outputs": [],
   "source": [
    "#downlad cifar data\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "del [x_test,y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "GFrSwPeCd-05"
   },
   "outputs": [],
   "source": [
    "#loop over each class label and sample 100 random images over each label and save the idx to subset\n",
    "np.random.seed(seed=222)\n",
    "idx=np.empty(0,dtype=\"int8\")\n",
    "for i in range(0,len(np.unique(y_train))):\n",
    "    idx=np.append(idx,np.random.choice(np.where((y_train[0:len(y_train)])==i)[0],100,replace=False))\n",
    "\n",
    "x_train= x_train[idx]\n",
    "y_train= y_train[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0B37tobId-06",
    "outputId": "6b4ebd97-bfac-48bb-8380-e145a0496b67"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 32, 32, 3)\n",
      "(1000, 1)\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([100, 100, 100, 100, 100, 100, 100, 100, 100, 100], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(np.unique(y_train,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "MmF8lJPed-07"
   },
   "outputs": [],
   "source": [
    "#make train valid and test\n",
    "#loop over each class label and sample 100 random images over each label and save the idx to subset\n",
    "np.random.seed(seed=123)\n",
    "idx_train=np.empty(0,dtype=\"int8\")\n",
    "for i in range(0,len(np.unique(y_train))):\n",
    "    idx_train=np.append(idx_train,np.random.choice(np.where((y_train[0:len(y_train)])==i)[0],10,replace=False))\n",
    "\n",
    "x_train_new = x_train[idx_train]\n",
    "y_train_new = y_train[idx_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uqiJHsodd-08"
   },
   "outputs": [],
   "source": [
    "x_test_new=(np.delete(x_train,idx_train,axis=0))\n",
    "y_test_new=(np.delete(y_train,idx_train,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "VuXfHWZvd-09"
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=127)\n",
    "idx_valid=np.empty(0,dtype=\"int8\")\n",
    "for i in range(0,len(np.unique(y_test_new))):\n",
    "    idx_valid=np.append(idx_valid,np.random.choice(np.where((y_test_new[0:len(y_test_new)])==i)[0],10,replace=False))\n",
    "\n",
    "x_valid_new = x_test_new[idx_valid]\n",
    "y_valid_new = y_test_new[idx_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "fPzf5eiOd-09"
   },
   "outputs": [],
   "source": [
    "x_test_new=(np.delete(x_test_new,idx_valid,axis=0))\n",
    "y_test_new=(np.delete(y_test_new,idx_valid,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "LAjRrwBFd-0-"
   },
   "outputs": [],
   "source": [
    "x_train_new = np.reshape(x_train_new, (100,32,32,3))\n",
    "x_valid_new = np.reshape(x_valid_new, (100,32,32,3))\n",
    "x_test_new = np.reshape(x_test_new, (800,32,32,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ub4bXw51d-0-",
    "outputId": "4fa50cbc-afce-4d6b-e5ed-09fcf59d8aff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([10, 10, 10, 10, 10, 10, 10, 10, 10, 10], dtype=int64))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([10, 10, 10, 10, 10, 10, 10, 10, 10, 10], dtype=int64))\n",
      "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([80, 80, 80, 80, 80, 80, 80, 80, 80, 80], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "print(np.unique(y_train_new,return_counts=True))\n",
    "print(np.unique(y_valid_new,return_counts=True))\n",
    "print(np.unique(y_test_new,return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XqAPBiZNd-0_"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical   \n",
    "\n",
    "y_train_new=to_categorical(y_train_new,10)\n",
    "y_valid_new=to_categorical(y_valid_new,10)\n",
    "y_test_new=to_categorical(y_test_new,10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pdQXPfHUd-0_",
    "outputId": "c506ce5a-a41e-464a-e303-156d8018949f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 32, 32, 3)\n",
      "(100, 10)\n",
      "(100, 32, 32, 3)\n",
      "(100, 10)\n",
      "(800, 32, 32, 3)\n",
      "(800, 10)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_new.shape)\n",
    "print(y_train_new.shape)\n",
    "\n",
    "print(x_valid_new.shape)\n",
    "print(y_valid_new.shape)\n",
    "\n",
    "print(x_test_new.shape)\n",
    "print(y_test_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "3hDsmjn4d-1A"
   },
   "outputs": [],
   "source": [
    "# center and standardize the data\n",
    "X_mean = np.mean( x_train_new, axis = 0)\n",
    "X_std = np.std( x_train_new, axis = 0)\n",
    "\n",
    "x_train_new = (x_train_new - X_mean ) / (X_std + 0.0001)\n",
    "x_valid_new = (x_valid_new - X_mean ) / (X_std + 0.0001)\n",
    "x_test_new = (x_test_new - X_mean ) / (X_std + 0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline 1: use raw images to train a Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape images for rf\n",
    "x_train_rf = x_train_new.reshape(len(x_train_new),32*32*3)\n",
    "x_valid_rf = x_valid_new.reshape(len(x_valid_new),32*32*3)\n",
    "x_test_rf = x_test_new.reshape(len(x_test_new),32*32*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(x_train_rf, np.argmax(y_train_new, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  2  7  4  1  4  2  8 12  6]\n",
      " [ 5 26  7  2  7  5  4  2  8 14]\n",
      " [ 6  3 14 10 12  5 11  9  7  3]\n",
      " [ 5  5  9 15  9  3  9 12  3 10]\n",
      " [ 5  5 12  5 23  6  7  9  5  3]\n",
      " [ 5  5  8 15  8  4  7 18  4  6]\n",
      " [ 2  5  7 13 17  1 16 15  2  2]\n",
      " [ 5  3  2  8 25 10  3 17  1  6]\n",
      " [11  9  3  6  2  1  0  6 30 12]\n",
      " [ 6 14  4  3  4  5  1  6 13 24]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25375"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = clf.predict(x_test_rf)\n",
    "print(confusion_matrix(np.argmax(y_test_new, axis=1), pred))\n",
    "np.sum(pred == np.argmax(y_test_new, axis=1)) / len(np.argmax(y_test_new, axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bmFjrUIxd-1B"
   },
   "source": [
    "## Setting up the the CNN classifier based on raw image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "9hOO4d4vd-1B"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, BatchNormalization\n",
    "from tensorflow.keras.layers import Convolution2D, MaxPooling2D, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "A6RNdedNd-1B"
   },
   "outputs": [],
   "source": [
    "# here we define hyperparameter of the NN\n",
    "batch_size = 10\n",
    "nb_classes = 10\n",
    "nb_epoch = 30\n",
    "img_rows, img_cols = 32, 32\n",
    "kernel_size = (3, 3)\n",
    "input_shape = (img_rows, img_cols, 3)\n",
    "pool_size = (2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "lqjynUYMd-1B"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Convolution2D(8,kernel_size,padding='same',input_shape=input_shape))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Convolution2D(8, kernel_size,padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "model.add(Convolution2D(16, kernel_size,padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Convolution2D(16,kernel_size,padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=pool_size))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(40))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U4cqyvwZd-1C",
    "outputId": "e32911dc-719c-475b-d5ee-1fe0e141287f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 32, 32, 8)         224       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 32, 32, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 8)         584       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 8)         32        \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 8)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 16, 16, 8)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 16, 16, 16)        1168      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 16)        2320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 16)        64        \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 8, 8, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 40)                41000     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 40)                160       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 40)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                410       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 46,058\n",
      "Trainable params: 45,882\n",
      "Non-trainable params: 176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M03zx5y4d-1D",
    "outputId": "4ec06aaf-34b2-401d-f42e-990a422ed049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "10/10 - 2s - loss: 2.7816 - accuracy: 0.0600 - val_loss: 2.2889 - val_accuracy: 0.1000\n",
      "Epoch 2/30\n",
      "10/10 - 1s - loss: 2.1237 - accuracy: 0.2400 - val_loss: 2.2922 - val_accuracy: 0.1100\n",
      "Epoch 3/30\n",
      "10/10 - 1s - loss: 1.7232 - accuracy: 0.4100 - val_loss: 2.2888 - val_accuracy: 0.1000\n",
      "Epoch 4/30\n",
      "10/10 - 1s - loss: 1.4993 - accuracy: 0.4400 - val_loss: 2.2759 - val_accuracy: 0.1200\n",
      "Epoch 5/30\n",
      "10/10 - 1s - loss: 1.3135 - accuracy: 0.6400 - val_loss: 2.2627 - val_accuracy: 0.1500\n",
      "Epoch 6/30\n",
      "10/10 - 1s - loss: 1.1685 - accuracy: 0.6900 - val_loss: 2.2608 - val_accuracy: 0.1500\n",
      "Epoch 7/30\n",
      "10/10 - 1s - loss: 1.0235 - accuracy: 0.7900 - val_loss: 2.2737 - val_accuracy: 0.1100\n",
      "Epoch 8/30\n",
      "10/10 - 1s - loss: 0.9387 - accuracy: 0.8900 - val_loss: 2.2844 - val_accuracy: 0.1000\n",
      "Epoch 9/30\n",
      "10/10 - 1s - loss: 0.9045 - accuracy: 0.8100 - val_loss: 2.3088 - val_accuracy: 0.1000\n",
      "Epoch 10/30\n",
      "10/10 - 1s - loss: 0.7858 - accuracy: 0.9200 - val_loss: 2.3236 - val_accuracy: 0.1000\n",
      "Epoch 11/30\n",
      "10/10 - 1s - loss: 0.6838 - accuracy: 0.9000 - val_loss: 2.3409 - val_accuracy: 0.1100\n",
      "Epoch 12/30\n",
      "10/10 - 1s - loss: 0.7220 - accuracy: 0.8800 - val_loss: 2.3720 - val_accuracy: 0.1200\n",
      "Epoch 13/30\n",
      "10/10 - 1s - loss: 0.6350 - accuracy: 0.9300 - val_loss: 2.3633 - val_accuracy: 0.1300\n",
      "Epoch 14/30\n",
      "10/10 - 1s - loss: 0.5617 - accuracy: 0.9600 - val_loss: 2.3353 - val_accuracy: 0.1000\n",
      "Epoch 15/30\n",
      "10/10 - 1s - loss: 0.5998 - accuracy: 0.9500 - val_loss: 2.3399 - val_accuracy: 0.1300\n",
      "Epoch 16/30\n",
      "10/10 - 1s - loss: 0.5506 - accuracy: 0.9400 - val_loss: 2.3688 - val_accuracy: 0.1300\n",
      "Epoch 17/30\n",
      "10/10 - 1s - loss: 0.4421 - accuracy: 0.9800 - val_loss: 2.3723 - val_accuracy: 0.1300\n",
      "Epoch 18/30\n",
      "10/10 - 1s - loss: 0.4314 - accuracy: 0.9700 - val_loss: 2.3722 - val_accuracy: 0.1100\n",
      "Epoch 19/30\n",
      "10/10 - 1s - loss: 0.3394 - accuracy: 0.9800 - val_loss: 2.3842 - val_accuracy: 0.1100\n",
      "Epoch 20/30\n",
      "10/10 - 1s - loss: 0.3708 - accuracy: 1.0000 - val_loss: 2.4053 - val_accuracy: 0.1300\n",
      "Epoch 21/30\n",
      "10/10 - 1s - loss: 0.3717 - accuracy: 0.9700 - val_loss: 2.4088 - val_accuracy: 0.1500\n",
      "Epoch 22/30\n",
      "10/10 - 1s - loss: 0.2695 - accuracy: 0.9900 - val_loss: 2.3951 - val_accuracy: 0.1600\n",
      "Epoch 23/30\n",
      "10/10 - 1s - loss: 0.3193 - accuracy: 0.9900 - val_loss: 2.3948 - val_accuracy: 0.1200\n",
      "Epoch 24/30\n",
      "10/10 - 1s - loss: 0.3064 - accuracy: 0.9600 - val_loss: 2.4113 - val_accuracy: 0.1300\n",
      "Epoch 25/30\n",
      "10/10 - 1s - loss: 0.2730 - accuracy: 0.9900 - val_loss: 2.4138 - val_accuracy: 0.1200\n",
      "Epoch 26/30\n",
      "10/10 - 1s - loss: 0.2121 - accuracy: 1.0000 - val_loss: 2.4385 - val_accuracy: 0.1400\n",
      "Epoch 27/30\n",
      "10/10 - 1s - loss: 0.2978 - accuracy: 0.9900 - val_loss: 2.4300 - val_accuracy: 0.1400\n",
      "Epoch 28/30\n",
      "10/10 - 1s - loss: 0.2698 - accuracy: 0.9900 - val_loss: 2.4399 - val_accuracy: 0.1100\n",
      "Epoch 29/30\n",
      "10/10 - 1s - loss: 0.3031 - accuracy: 0.9900 - val_loss: 2.4600 - val_accuracy: 0.1300\n",
      "Epoch 30/30\n",
      "10/10 - 1s - loss: 0.2147 - accuracy: 0.9900 - val_loss: 2.4859 - val_accuracy: 0.1500\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train_new, y_train_new, \n",
    "                  batch_size=10, \n",
    "                  epochs=30,\n",
    "                  verbose=2, \n",
    "                  validation_data=(x_valid_new, y_valid_new),shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j7kEbIcad-1D"
   },
   "source": [
    "### Evaluation of the CNN classifier that was trained on raw image data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xYcyO4N4d-1E",
    "outputId": "6eea955c-6096-4c5c-d920-1619f966b1d7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[35  4  2 10  4  0  1  7 13  4]\n",
      " [11  9  4  5 11 10  3 10  5 12]\n",
      " [ 3  3 12  7 24  9  5  5  9  3]\n",
      " [ 3  2 15 20 15  7  2  5  8  3]\n",
      " [ 1  1 13  7 28  3  3  5 14  5]\n",
      " [ 4  1  6 19 19  6  1 14  9  1]\n",
      " [ 3  3 15  7 25  8 12  2  3  2]\n",
      " [ 4  1  5 17 20  6  0 16  7  4]\n",
      " [ 8  4 11  2  4  6  1  9 29  6]\n",
      " [ 6 14  7  3  9  4  1 10  8 18]]\n",
      "Acc =  0.23125\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = model.predict(x_test_new)\n",
    "print(confusion_matrix(np.argmax(y_test_new,axis=1), np.argmax(pred,axis=1)))\n",
    "print(\"Acc = \" ,np.sum(np.argmax(y_test_new,axis=1)==np.argmax(pred,axis=1))/len(y_test_new))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i5k7FBald-1E"
   },
   "source": [
    "## Getting the VGG features for CIFAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fQH8us4Bd-1F",
    "outputId": "53faef3e-5f2b-49bb-b6e2-eedf3a344cc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Datentr„ger in Laufwerk C: ist Windows\n",
      " Volumeseriennummer: 6A65-4827\n",
      "\n",
      " Verzeichnis von C:\\Users\\brdd\\Documents\\GitHub\\dl_course_2023\\notebooks\n",
      "\n",
      "\n",
      " Verzeichnis von C:\\Users\\brdd\\Documents\\GitHub\\dl_course_2023\\notebooks\n",
      "\n",
      "07.03.2023  09:59        17'840'468 cifar_EMB_1000.npz\n",
      "               1 Datei(en),     17'840'468 Bytes\n",
      "               0 Verzeichnis(se), 242'575'511'552 Bytes frei\n"
     ]
    }
   ],
   "source": [
    "# Downloading embeddings\n",
    "import urllib\n",
    "import os\n",
    "if not os.path.isfile('cifar_EMB_1000.npz'):\n",
    "    urllib.request.urlretrieve(\n",
    "    \"https://www.dropbox.com/s/si287al91c1ls0d/cifar_EMB_1000.npz?dl=1\",\n",
    "    \"cifar_EMB_1000.npz\")\n",
    "%ls -hl cifar_EMB_1000.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "bux3xwf0d-1F"
   },
   "outputs": [],
   "source": [
    "Data=np.load(\"cifar_EMB_1000.npz\")\n",
    "vgg_features_cifar = Data[\"arr_0\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "gFUrY5ekd-1F"
   },
   "outputs": [],
   "source": [
    "vgg_features_cifar_train = vgg_features_cifar[idx_train]\n",
    "vgg_features_cifar_test=(np.delete(vgg_features_cifar,idx_train,axis=0))\n",
    "vgg_features_cifar_valid = vgg_features_cifar_test[idx_valid]\n",
    "vgg_features_cifar_test=(np.delete(vgg_features_cifar_test,idx_valid,axis=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AZCEIourd-1G",
    "outputId": "8c5981ab-f219-44e3-e04a-eb7ae77bffee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 4096)\n",
      "(100, 4096)\n",
      "(800, 4096)\n"
     ]
    }
   ],
   "source": [
    "print(vgg_features_cifar_train.shape)\n",
    "print(vgg_features_cifar_valid.shape)\n",
    "print(vgg_features_cifar_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8ym3NgNd-1I"
   },
   "source": [
    "## Baseline 2: use VGG feature to train a Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "04ljtLiwd-1I",
    "outputId": "f67dfb42-b7a1-49fb-ea38-c44ddceba6d7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(vgg_features_cifar_train,np.argmax(y_train_new, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DMsIVx7zd-1J",
    "outputId": "22b48f25-6db9-467f-fa09-abd4b7b7aa52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[39  2  2  0  2  0  1  1 25  8]\n",
      " [ 0 62  1  1  1  1  0  0  3 11]\n",
      " [ 6  1 30 13 10  9  5  3  2  1]\n",
      " [ 2  1  4 27  0 14 24  3  0  5]\n",
      " [ 5  0  9  2 40  3  9  8  2  2]\n",
      " [ 1  0  2 27  5 38  3  3  0  1]\n",
      " [ 2  0 17  1  5  4 48  2  1  0]\n",
      " [ 1  0  1  8 15  4  0 48  1  2]\n",
      " [ 5  2  0  2  0  1  1  0 62  7]\n",
      " [ 0 18  0  0  0  0  1  0  5 56]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5625"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred=clf.predict(vgg_features_cifar_test)\n",
    "print(confusion_matrix(np.argmax(y_test_new, axis=1), pred))\n",
    "np.sum(pred==np.argmax(y_test_new, axis=1))/len(np.argmax(y_test_new, axis=1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXkrEaXKd-1G"
   },
   "source": [
    "## Setting up the the NN classifier based on VGG feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "KN12Ss4md-1H"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(200,batch_input_shape=(None, 4096)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(200))\n",
    "\n",
    "#### we still need to add the last layers to get the predictions on the 10 classes\n",
    "### your code here\n",
    "\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "####### end of your code ######\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ziQXpgHtd-1H",
    "outputId": "c1533b58-9f44-4af2-efd8-cd797b88618a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 200)               819400    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 200)               800       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 200)               40200     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 10)                2010      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 862,410\n",
      "Trainable params: 862,010\n",
      "Non-trainable params: 400\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QK45pvVCd-1H",
    "outputId": "5d60bf78-eb8c-4864-905e-b6bdfd780542"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 - 1s - loss: 2.6514 - accuracy: 0.2300 - val_loss: 7.6833 - val_accuracy: 0.2800\n",
      "Epoch 2/20\n",
      "10/10 - 0s - loss: 0.9340 - accuracy: 0.6800 - val_loss: 4.9032 - val_accuracy: 0.3500\n",
      "Epoch 3/20\n",
      "10/10 - 0s - loss: 0.6010 - accuracy: 0.8100 - val_loss: 3.2697 - val_accuracy: 0.4700\n",
      "Epoch 4/20\n",
      "10/10 - 0s - loss: 0.5742 - accuracy: 0.8300 - val_loss: 2.6853 - val_accuracy: 0.4700\n",
      "Epoch 5/20\n",
      "10/10 - 0s - loss: 0.4067 - accuracy: 0.8700 - val_loss: 2.3595 - val_accuracy: 0.4900\n",
      "Epoch 6/20\n",
      "10/10 - 0s - loss: 0.4187 - accuracy: 0.8800 - val_loss: 2.1491 - val_accuracy: 0.5000\n",
      "Epoch 7/20\n",
      "10/10 - 0s - loss: 0.2045 - accuracy: 0.9500 - val_loss: 1.9905 - val_accuracy: 0.4900\n",
      "Epoch 8/20\n",
      "10/10 - 0s - loss: 0.2516 - accuracy: 0.9300 - val_loss: 2.1082 - val_accuracy: 0.5300\n",
      "Epoch 9/20\n",
      "10/10 - 0s - loss: 0.1757 - accuracy: 0.9500 - val_loss: 1.9797 - val_accuracy: 0.5400\n",
      "Epoch 10/20\n",
      "10/10 - 0s - loss: 0.1777 - accuracy: 0.9500 - val_loss: 1.8250 - val_accuracy: 0.5400\n",
      "Epoch 11/20\n",
      "10/10 - 0s - loss: 0.1514 - accuracy: 0.9800 - val_loss: 1.8680 - val_accuracy: 0.5300\n",
      "Epoch 12/20\n",
      "10/10 - 0s - loss: 0.1167 - accuracy: 0.9700 - val_loss: 1.7584 - val_accuracy: 0.5200\n",
      "Epoch 13/20\n",
      "10/10 - 0s - loss: 0.1016 - accuracy: 1.0000 - val_loss: 1.7354 - val_accuracy: 0.5200\n",
      "Epoch 14/20\n",
      "10/10 - 0s - loss: 0.1206 - accuracy: 0.9800 - val_loss: 1.7551 - val_accuracy: 0.5500\n",
      "Epoch 15/20\n",
      "10/10 - 0s - loss: 0.1456 - accuracy: 0.9700 - val_loss: 1.7722 - val_accuracy: 0.5200\n",
      "Epoch 16/20\n",
      "10/10 - 0s - loss: 0.0952 - accuracy: 0.9800 - val_loss: 1.7201 - val_accuracy: 0.4800\n",
      "Epoch 17/20\n",
      "10/10 - 0s - loss: 0.0646 - accuracy: 0.9900 - val_loss: 1.7496 - val_accuracy: 0.5300\n",
      "Epoch 18/20\n",
      "10/10 - 0s - loss: 0.0824 - accuracy: 0.9800 - val_loss: 1.7048 - val_accuracy: 0.5200\n",
      "Epoch 19/20\n",
      "10/10 - 0s - loss: 0.0520 - accuracy: 1.0000 - val_loss: 1.7755 - val_accuracy: 0.4900\n",
      "Epoch 20/20\n",
      "10/10 - 0s - loss: 0.0526 - accuracy: 0.9900 - val_loss: 1.8437 - val_accuracy: 0.4900\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(vgg_features_cifar_train, y_train_new, \n",
    "                  batch_size=10, \n",
    "                  epochs=20,\n",
    "                  verbose=2, \n",
    "                  validation_data=(vgg_features_cifar_valid, y_valid_new),shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AlHwGiRsd-1I"
   },
   "source": [
    "### Evaluation of the NN classifier that was trained on VGG features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "80mCdjkWd-1I",
    "outputId": "d491e0cf-944d-404e-fd39-df1a99725e89"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[42  1  3  1  1  2  0  2 23  5]\n",
      " [ 1 56  2  0  1  3  0  1  1 15]\n",
      " [ 7  0 31  2 13 18  2  3  3  1]\n",
      " [ 0  0  3 26  2 30  7  2  4  6]\n",
      " [ 0  0  3  5 46  4  1 14  4  3]\n",
      " [ 0  0  0 16  5 52  3  4  0  0]\n",
      " [ 2  0 25  2 11  8 29  2  1  0]\n",
      " [ 1  0  1  5 15  6  0 50  1  1]\n",
      " [ 3  1  1  1  0  3  1  2 63  5]\n",
      " [ 1 13  0  0  1  1  0  0  2 62]]\n",
      "Acc =  0.57125\n"
     ]
    }
   ],
   "source": [
    "pred=model.predict(vgg_features_cifar_test)\n",
    "\n",
    "#### we now want to get the confusion matrix for the predictions on the test data\n",
    "### your code here\n",
    "\n",
    "print(confusion_matrix(np.argmax(y_test_new,axis=1),np.argmax(pred,axis=1)))\n",
    "print(\"Acc = \" ,np.sum(np.argmax(y_test_new,axis=1)==np.argmax(pred,axis=1))/len(y_test_new))\n",
    "\n",
    "########## end of your code ###############################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "26ZX9Kqdd-1J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "08_classification_few_labels_sol.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
