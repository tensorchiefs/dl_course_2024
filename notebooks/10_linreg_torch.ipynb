{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2sP8Kwe7L9Z"
   },
   "source": [
    "## Fitting a linear regression model with TensorFlow\n",
    "\n",
    "In this notebook you will see how to use TensorFlow to fit the parameters (slope and intercept) of a simple linear regression model via gradient descent (GD). \n",
    "\n",
    "**Dataset:** You work with the systolic blood pressure and age data of 33 American women, which is generated and visualized in the upper part of the notebook. \n",
    "\n",
    "**Content:**\n",
    "\n",
    "* fit a linear model via the sklearn machine learning library of python to get the fitted values of the intercept and slope as reference. \n",
    "* use the TensorFlow library to fit the parameter of the simple linear model via GD with the objective to minimize the MSE loss. \n",
    "    * define the computational graph of the model\n",
    "    * define the loss and the optimizer\n",
    "    * visualize the computational graph in tensorboard\n",
    "    * fit the model parameters via GD and check the current values of the estimated model parameters and the loss after each updatestep\n",
    "    * verify that the estimated parameters converge to the values which you got from the sklearn fit.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxDnHMLUL64a"
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, slope: 0.05530909448862076, intercept: 138.9999237060547, mse: 673.4545288085938\n",
      "Epoch: 1, slope: 0.08415231853723526, intercept: 138.9993438720703, mse: 650.182373046875\n",
      "Epoch: 2, slope: 0.0991988405585289, intercept: 138.9984893798828, mse: 643.8486328125\n",
      "Epoch: 3, slope: 0.10705311596393585, intercept: 138.99749755859375, mse: 642.1177978515625\n",
      "Epoch: 5000, slope: 0.2193760722875595, intercept: 133.61346435546875, mse: 583.372802734375\n",
      "Epoch: 10000, slope: 0.31234320998191833, intercept: 128.79087829589844, mse: 536.7905883789062\n",
      "Epoch: 15000, slope: 0.39555972814559937, intercept: 124.47410583496094, mse: 499.4712219238281\n",
      "Epoch: 20000, slope: 0.4700349271297455, intercept: 120.61077117919922, mse: 469.5780029296875\n",
      "Epoch: 25000, slope: 0.5366916060447693, intercept: 117.15301513671875, mse: 445.6317138671875\n",
      "Epoch: 30000, slope: 0.596350371837616, intercept: 114.05827331542969, mse: 426.4493408203125\n",
      "Epoch: 35000, slope: 0.649747908115387, intercept: 111.28832244873047, mse: 411.0822448730469\n",
      "Epoch: 40000, slope: 0.6975436806678772, intercept: 108.80897521972656, mse: 398.77142333984375\n",
      "Epoch: 45000, slope: 0.74030601978302, intercept: 106.59071350097656, mse: 388.9129943847656\n",
      "Epoch: 50000, slope: 0.7785924077033997, intercept: 104.60464477539062, mse: 381.0130920410156\n",
      "Epoch: 55000, slope: 0.8128533959388733, intercept: 102.82738494873047, mse: 374.68572998046875\n",
      "Epoch: 60000, slope: 0.8435359001159668, intercept: 101.23576354980469, mse: 369.614013671875\n",
      "Epoch: 65000, slope: 0.8709756731987, intercept: 99.81234741210938, mse: 365.5546875\n",
      "Epoch: 70000, slope: 0.8955512046813965, intercept: 98.53750610351562, mse: 362.3004455566406\n",
      "Epoch: 75000, slope: 0.9175289869308472, intercept: 97.3974380493164, mse: 359.6958923339844\n",
      "Epoch: 80000, slope: 0.9372106194496155, intercept: 96.37647247314453, mse: 357.60809326171875\n",
      "Epoch: 85000, slope: 0.9548285603523254, intercept: 95.4625473022461, mse: 355.935546875\n",
      "Epoch: 90000, slope: 0.9705849289894104, intercept: 94.64521026611328, mse: 354.59661865234375\n",
      "Epoch: 95000, slope: 0.9846839904785156, intercept: 93.91383361816406, mse: 353.52423095703125\n",
      "Epoch: 100000, slope: 0.9973174929618835, intercept: 93.25848388671875, mse: 352.6640319824219\n",
      "Epoch: 105000, slope: 1.0086556673049927, intercept: 92.6703109741211, mse: 351.9732666015625\n",
      "Epoch: 110000, slope: 1.0187182426452637, intercept: 92.14833068847656, mse: 351.4245300292969\n",
      "Epoch: 115000, slope: 1.0278054475784302, intercept: 91.67694091796875, mse: 350.98089599609375\n",
      "Epoch: 120000, slope: 1.0359222888946533, intercept: 91.25589752197266, mse: 350.6263427734375\n",
      "Epoch: 125000, slope: 1.0431511402130127, intercept: 90.88090515136719, mse: 350.3437194824219\n",
      "Epoch: 130000, slope: 1.049646019935608, intercept: 90.54399108886719, mse: 350.1163330078125\n",
      "Epoch: 135000, slope: 1.0554990768432617, intercept: 90.24037170410156, mse: 349.9330749511719\n",
      "Epoch: 140000, slope: 1.060646414756775, intercept: 89.97334289550781, mse: 349.7886657714844\n",
      "Epoch: 145000, slope: 1.065240740776062, intercept: 89.73502349853516, mse: 349.6733093261719\n",
      "Epoch: 150000, slope: 1.0694693326950073, intercept: 89.51567077636719, mse: 349.5782775878906\n",
      "Epoch: 155000, slope: 1.073146104812622, intercept: 89.32493591308594, mse: 349.50421142578125\n",
      "Epoch: 160000, slope: 1.0764949321746826, intercept: 89.15122985839844, mse: 349.44378662109375\n",
      "Epoch: 165000, slope: 1.0794363021850586, intercept: 88.99864196777344, mse: 349.3962707519531\n",
      "Epoch: 170000, slope: 1.082236886024475, intercept: 88.8533706665039, mse: 349.3558349609375\n",
      "Epoch: 175000, slope: 1.0844429731369019, intercept: 88.73892974853516, mse: 349.3272705078125\n",
      "Epoch: 180000, slope: 1.086648941040039, intercept: 88.6244888305664, mse: 349.3016662597656\n",
      "Epoch: 185000, slope: 1.0887184143066406, intercept: 88.51715087890625, mse: 349.2802429199219\n",
      "Epoch: 190000, slope: 1.0901890993118286, intercept: 88.44085693359375, mse: 349.2665100097656\n",
      "Epoch: 195000, slope: 1.091659665107727, intercept: 88.36456298828125, mse: 349.254150390625\n",
      "Epoch: 200000, slope: 1.0931304693222046, intercept: 88.28826904296875, mse: 349.2430725097656\n",
      "Epoch: 205000, slope: 1.094601035118103, intercept: 88.21197509765625, mse: 349.2332763671875\n",
      "Epoch: 210000, slope: 1.095573902130127, intercept: 88.1615219116211, mse: 349.2275085449219\n",
      "Epoch: 215000, slope: 1.0963093042373657, intercept: 88.12337493896484, mse: 349.22357177734375\n",
      "Epoch: 220000, slope: 1.097044587135315, intercept: 88.0852279663086, mse: 349.219970703125\n",
      "Epoch: 225000, slope: 1.0977799892425537, intercept: 88.04708099365234, mse: 349.216552734375\n",
      "Epoch: 230000, slope: 1.098515272140503, intercept: 88.0089340209961, mse: 349.2135314941406\n",
      "Epoch: 235000, slope: 1.0992506742477417, intercept: 87.97078704833984, mse: 349.2108154296875\n",
      "Epoch: 240000, slope: 1.099985957145691, intercept: 87.9326400756836, mse: 349.20843505859375\n",
      "Epoch: 245000, slope: 1.1007213592529297, intercept: 87.89449310302734, mse: 349.2063903808594\n",
      "Epoch: 250000, slope: 1.101456642150879, intercept: 87.8563461303711, mse: 349.20465087890625\n",
      "Epoch: 255000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 260000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 265000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 270000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 275000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 280000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 285000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 290000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 295000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 300000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 305000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 310000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 315000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 320000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 325000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 330000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 335000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 340000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 345000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 350000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 355000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 360000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 365000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 370000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 375000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 380000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 385000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 390000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 395000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 400000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 405000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 410000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 415000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 420000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 425000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 430000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 435000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 440000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 445000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 450000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 455000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 460000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 465000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 470000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 475000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 480000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 485000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 490000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n",
      "Epoch: 495000, slope: 1.101706624031067, intercept: 87.84339141845703, mse: 349.2041015625\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# Data\n",
    "x_data = np.array([22, 41, 52, 23, 41, 54, 24, 46, 56, 27, 47, 57, 28, 48, 58, 9,\n",
    "                   49, 59, 30, 49, 63, 32, 50, 67, 33, 51, 71, 35, 51, 77, 40, 51, 81], np.float32)\n",
    "y_data = np.array([131, 139, 128, 128, 171, 105, 116, 137, 145, 106, 111, 141, 114,\n",
    "                   115, 153, 123, 133, 157, 117, 128, 155, 122, 183, 176, 99, 130, 172, \n",
    "                   121, 133, 178, 147, 144, 217], np.float32)\n",
    "\n",
    "x = torch.tensor(x_data, requires_grad=False)\n",
    "y = torch.tensor(y_data, requires_grad=False)\n",
    "\n",
    "# Variables\n",
    "a = torch.tensor([0.0], requires_grad=True)  # slope\n",
    "b = torch.tensor([139.0], requires_grad=True)  # intercept\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.SGD([a, b], lr=0.0001)\n",
    "\n",
    "# Training loop\n",
    "for i in range(500_000):\n",
    "    optimizer.zero_grad()  # Reset gradients to zero; necessary before backprop\n",
    "    y_hat = a * x + b  # Model prediction\n",
    "    loss = torch.mean((y - y_hat) ** 2)  # Mean squared error\n",
    "    \n",
    "    loss.backward()  # Compute gradients\n",
    "    optimizer.step()  # Update parameters\n",
    "    \n",
    "    if i in [1, 2, 3] or i % 5000 == 0:\n",
    "        print(f\"Epoch: {i}, slope: {a.item()}, intercept: {b.item()}, mse: {loss.item()}\")\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "10_linreg_tensorflow.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
