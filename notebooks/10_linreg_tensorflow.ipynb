{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O2sP8Kwe7L9Z"
   },
   "source": [
    "## Fitting a linear regression model with TensorFlow\n",
    "\n",
    "In this notebook you will see how to use TensorFlow to fit the parameters (slope and intercept) of a simple linear regression model via gradient descent (GD). \n",
    "\n",
    "**Dataset:** You work with the systolic blood pressure and age data of 33 American women, which is generated and visualized in the upper part of the notebook. \n",
    "\n",
    "**Content:**\n",
    "\n",
    "* fit a linear model via the sklearn machine learning library of python to get the fitted values of the intercept and slope as reference. \n",
    "* use the TensorFlow library to fit the parameter of the simple linear model via GD with the objective to minimize the MSE loss. \n",
    "    * define the computational graph of the model\n",
    "    * define the loss and the optimizer\n",
    "    * visualize the computational graph in tensorboard\n",
    "    * fit the model parameters via GD and check the current values of the estimated model parameters and the loss after each updatestep\n",
    "    * verify that the estimated parameters converge to the values which you got from the sklearn fit.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IxDnHMLUL64a"
   },
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2Ns6420jRmbQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "plt.style.use('default')\n",
    "from sklearn.linear_model import LinearRegression\n",
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p3c9bh7zMVhP"
   },
   "source": [
    "Here we read in the systolic blood pressure and the age of the 33 American women in our dataset. Then we use the sklearn library to find the optimal values for the slope a and the intercept b."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5NlSPsPSFR-"
   },
   "outputs": [],
   "source": [
    "# Blood Pressure data\n",
    "x = [22, 41, 52, 23, 41, 54, 24, 46, 56, 27, 47, 57, 28, 48, 58,  9, \n",
    "     49, 59, 30, 49, 63, 32, 50, 67, 33, 51, 71, 35, 51, 77, 40, 51, 81]\n",
    "y = [131, 139, 128, 128, 171, 105, 116, 137, 145, 106, 111, 141, 114, \n",
    "     115, 153, 123, 133, 157, 117, 128, 155, 122, 183,\n",
    "     176,  99, 130, 172, 121, 133, 178, 147, 144, 217] \n",
    "x = np.asarray(x, np.float32) \n",
    "y = np.asarray(y, np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 489
    },
    "id": "cFR-y-HER-Uo",
    "outputId": "0f735317-dec1-4177-af0f-a35293fa2079"
   },
   "outputs": [],
   "source": [
    "plt.scatter(x=x,y=y)\n",
    "plt.title(\"blood pressure vs age\")\n",
    "plt.xlabel(\"x (age)\")\n",
    "plt.ylabel(\"y (sbp)\")\n",
    "\n",
    "model = LinearRegression()\n",
    "res = model.fit(x.reshape((len(x),1)), y)\n",
    "predictions = model.predict(x.reshape((len(x),1)))\n",
    "plt.plot(x, predictions)\n",
    "plt.show()\n",
    "print(\"intercept = \",res.intercept_,\"solpe = \", res.coef_[0],)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oxlyNp9uSKYd"
   },
   "source": [
    "## Tensorflow\n",
    "\n",
    "We now use Tensorflow to define the computational graph then we will run the graph and automatically get the gradients of the loss w.r.t the variables (slope a  and intercept b) to update them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LiNOds2vSOz8",
    "outputId": "9a222e19-aa5d-4adc-e6ab-9369d48454a2"
   },
   "outputs": [],
   "source": [
    "# Defining the graph (construction phase)\n",
    "\n",
    "@tf.function\n",
    "def my_func(a_, b_, example = None):\n",
    "  if (example == None):\n",
    "    x_  = tf.constant(x, name='x_const')                 # Constants, these are fixed tensors holding the data values and cannot be changed by the optimization\n",
    "    y_  = tf.constant(y, name='y_const')  \n",
    "  else:\n",
    "    x_  = tf.constant(x[example], name='x_const')                 # Constants, these are fixed tensors holding the data values and cannot be changed by the optimization\n",
    "    y_  = tf.constant(y[example], name='y_const')  \n",
    "\n",
    "  y_hat_ = a_*x_ + b_                                      # we symbolically calculate y_hat    \n",
    "  loss_ = tf.reduce_mean(tf.square(y_ - y_hat_))           # The final result, the MSE. Still symbolical\n",
    "  return loss_\n",
    "\n",
    "a_  = tf.Variable(0.0, name='a_var')                       # Variables, with starting values, will be optimized later\n",
    "b_  = tf.Variable(139.0, name='b_var')                     # we name them so that they look nicer in the graph\n",
    "\n",
    "logdir=\"linreg/\"\n",
    "writer = tf.summary.create_file_writer(logdir)\n",
    "tf.summary.trace_on(graph=True, profiler=True)\n",
    "z = my_func(a_, b_)   #needs one call to write the graph\n",
    "with writer.as_default():\n",
    "  tf.summary.trace_export( \n",
    "      name=\"linreg_tensorboard\",\n",
    "      step=0,\n",
    "      profiler_outdir=logdir)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It coult be that tensorboard does not work. Do not worry to much about it.  \n",
    "You can also try to disable the enhanced tracking protection of your browser."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgPGU_evyTvw"
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir linreg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nkS4XL2QtxJk"
   },
   "source": [
    "Let's run the Graph and feed our start values for slope a and intercept b and fetch the mse loss\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uSVZm4EBu5MQ"
   },
   "source": [
    "In the lecture and in the [book](https://www.manning.com/books/probabilistic-deep-learning) around figure 3.12. We calculated an single example by hand. In that example we had x=58 and y=153. This corresponds to the entry number 14\n",
    "Let's first check if this the example has been calculated correctly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xN5I06nLuJio",
    "outputId": "d3aa0667-557e-4058-d36a-466ef075ba68"
   },
   "outputs": [],
   "source": [
    "#In the lecture we calculated the loss for example number 14\n",
    "x[14], y[14] #Should be 58 and 153"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "91qRdJJkqNrY",
    "outputId": "4de0bcb7-f0de-4c70-d5b6-9be2083543f1"
   },
   "outputs": [],
   "source": [
    "res_val =my_func(a_, b_, example=14)         # Letting the variables a=0 b=139 flow through the graph\n",
    "res_val\n",
    "res_val.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GTUpLkDhvb8b"
   },
   "source": [
    "Let's calculate the gradient of the loss function w.r.t. a and b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e0YJD4J3uwZw",
    "outputId": "078b00ab-59f7-4b9b-9620-d186cf2138f1"
   },
   "outputs": [],
   "source": [
    "#The gradient w.r.t. and be \n",
    "a_  = tf.Variable(0.0, name='a_var')                       # Variables, with starting values\n",
    "b_  = tf.Variable(139.0, name='b_var')  \n",
    "with tf.GradientTape() as tape:\n",
    "    loss = my_func(a_,b_, 14)\n",
    "    print(tape.gradient(loss, [a_,b_]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RmVO643pRWzM"
   },
   "source": [
    "Now we add an optimizer (gradient descent) to the graph and opimize the slope a and the intercept b. The start values are a=0 and b=139 (139 is the mean of the blood pressure and slope a=0 implies that the model predicts the mean for each age). We set a learning rate  and do 80000 updatesteps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o2StYA16v4vL",
    "outputId": "b08d5373-4487-43de-8321-da038944df8a"
   },
   "outputs": [],
   "source": [
    "a_  = tf.Variable(0.0, name='a_var')                       # Variables, with starting values\n",
    "b_  = tf.Variable(139.0, name='b_var')                     # \n",
    "optimizer =   tf.keras.optimizers.SGD(0.0001)             # sgd optimizer with the learning rate\n",
    "for i in range(80_000): \n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = my_func(a_,b_)\n",
    "    gradients = tape.gradient(loss, [a_,b_])\n",
    "    optimizer.apply_gradients(zip(gradients,[a_,b_])) \n",
    "    if ((i==1)|(i==2)|(i==3)): \n",
    "      print(\"Epoch:\",i, \"slope=\",a_.numpy(),\"intercept=\",b_.numpy(), \"mse=\", loss.numpy()) \n",
    "    if (i % 5000 == 0): \n",
    "      print(\"Epoch:\",i, \"slope=\",a_.numpy(),\"intercept=\",b_.numpy(), \"mse=\", loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZgcbnOFVRxs"
   },
   "source": [
    "Let's look at the final values for the slope a and the intercept b. Form the sklearn solution we know that:\n",
    "\n",
    "1.   optimal value for a:   1.1050216\n",
    "2.   optimal value for b:   87.67143\n",
    "3.   minimal loss:         349.200787168560\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ElBejUYn0u7Q",
    "outputId": "eacec731-443a-4359-b52c-f578dea91cb9"
   },
   "outputs": [],
   "source": [
    "print(a_.numpy(), b_.numpy(), loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TMqiXRZ9EMfh"
   },
   "source": [
    "#### Exercise\n",
    "\n",
    "Compare the optimal values from tensorflow with the ones from sklearn.  \n",
    "Do you get the same?    \n",
    "Try to explain the differences and change the code to get the same results.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V164z0rB4h1K"
   },
   "outputs": [],
   "source": [
    "# @title Answers\n",
    "\n",
    "a_  = tf.Variable(0.0, name='a_var')                       # Variables, with starting values\n",
    "b_  = tf.Variable(139.0, name='b_var')                     # \n",
    "optimizer =   tf.keras.optimizers.Adam()#  changed the optimizer to Adam\n",
    "for i in range(80_000): \n",
    "  with tf.GradientTape() as tape:\n",
    "    loss = my_func(a_,b_)\n",
    "    gradients = tape.gradient(loss, [a_,b_])\n",
    "    optimizer.apply_gradients(zip(gradients,[a_,b_])) \n",
    "    if ((i==1)|(i==2)|(i==3)): \n",
    "      print(\"Epoch:\",i, \"slope=\",a_.numpy(),\"intercept=\",b_.numpy(), \"mse=\", loss.numpy()) \n",
    "    if (i % 5000 == 0): \n",
    "      print(\"Epoch:\",i, \"slope=\",a_.numpy(),\"intercept=\",b_.numpy(), \"mse=\", loss.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Solutions!</summary>\n",
    "  - The SDG does not find the optimal solutions that quick, however it  is very close, if you change the learning rate or train longer, you  will get the optimal solution as well. \n",
    "  - The Adam Optimizer reaches the optimum after some steps by dynamically adapting the gradients.\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "10_linreg_tensorflow.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
